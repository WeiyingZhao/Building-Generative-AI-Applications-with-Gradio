{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPTh1dvyXPcVt9nFnyu806S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# L3: Image generation app ðŸŽ¨"],"metadata":{"id":"wMu6DJFw_e-_"}},{"cell_type":"markdown","source":["Load your HF API key and relevant Python libraries"],"metadata":{"id":"AHslSLzH_j3K"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRHZoEeE_VsJ"},"outputs":[],"source":["import os\n","import io\n","import IPython.display\n","from PIL import Image\n","import base64\n","# from dotenv import load_dotenv, find_dotenv\n","# _ = load_dotenv(find_dotenv()) # read local .env file\n","# hf_api_key = os.environ['HF_API_KEY']"]},{"cell_type":"code","source":["# # Helper function\n","# import requests, json\n","\n","# #Text-to-image endpoint\n","# def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n","#     headers = {\n","#       \"Authorization\": f\"Bearer {hf_api_key}\",\n","#       \"Content-Type\": \"application/json\"\n","#     }\n","#     data = { \"inputs\": inputs }\n","#     if parameters is not None:\n","#         data.update({\"parameters\": parameters})\n","#     response = requests.request(\"POST\",\n","#                                 ENDPOINT_URL,\n","#                                 headers=headers,\n","#                                 data=json.dumps(data))\n","#     return json.loads(response.content.decode(\"utf-8\"))"],"metadata":{"id":"ptzZ3t4o_nVk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Building an image generation app"],"metadata":{"id":"gxooBnUo_pzo"}},{"cell_type":"markdown","source":["Here we are going to run `runwayml/stable-diffusion-v1-5` using the `ðŸ§¨ diffusers` library."],"metadata":{"id":"S6ySuc29_r2Y"}},{"cell_type":"markdown","source":["### How about running it locally?\n","The code would look very similar if you were running it locally instead of from an API.\n","```py\n","from diffusers import DiffusionPipeline\n","\n","pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n","\n","def get_completion(prompt):\n","    return pipeline(prompt).images[0]    \n","```"],"metadata":{"id":"ScMzUVxv_u6-"}},{"cell_type":"code","source":["from diffusers import DiffusionPipeline\n","\n","pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n","\n","def get_completion(prompt):\n","    return pipeline(prompt).images[0]"],"metadata":{"id":"JBFahgvd_wxP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"a dog in a park\"\n","\n","result = get_completion(prompt)\n","IPython.display.HTML(f'<img src=\"data:image/png;base64,{result}\" />')"],"metadata":{"id":"Al3eAFzU_yow"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generating with `gr.Interface()`"],"metadata":{"id":"XVB1o4nt_sd9"}},{"cell_type":"code","source":["import gradio as gr\n","\n","#A helper function to convert the PIL image to base64\n","#so you can send it to the API\n","def base64_to_pil(img_base64):\n","    base64_decoded = base64.b64decode(img_base64)\n","    byte_stream = io.BytesIO(base64_decoded)\n","    pil_image = Image.open(byte_stream)\n","    return pil_image\n","\n","def generate(prompt):\n","    output = get_completion(prompt)\n","    result_image = base64_to_pil(output)\n","    return result_image\n","\n","gr.close_all()\n","demo = gr.Interface(fn=generate,\n","                    inputs=[gr.Textbox(label=\"Your prompt\")],\n","                    outputs=[gr.Image(label=\"Result\")],\n","                    title=\"Image Generation with Stable Diffusion\",\n","                    description=\"Generate any image with Stable Diffusion\",\n","                    allow_flagging=\"never\",\n","                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n","\n","demo.launch(share=True, server_port=int(os.environ['PORT1']))"],"metadata":{"id":"q2x7hXUB_2ce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo.close()"],"metadata":{"id":"dr-mWzJ3_5rR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Building a more advanced interface"],"metadata":{"id":"zOBtNWUP_7nP"}},{"cell_type":"code","source":["import gradio as gr\n","\n","#A helper function to convert the PIL image to base64\n","# so you can send it to the API\n","def base64_to_pil(img_base64):\n","    base64_decoded = base64.b64decode(img_base64)\n","    byte_stream = io.BytesIO(base64_decoded)\n","    pil_image = Image.open(byte_stream)\n","    return pil_image\n","\n","def generate(prompt, negative_prompt, steps, guidance, width, height):\n","    params = {\n","        \"negative_prompt\": negative_prompt,\n","        \"num_inference_steps\": steps,\n","        \"guidance_scale\": guidance,\n","        \"width\": width,\n","        \"height\": height\n","    }\n","\n","    output = get_completion(prompt, params)\n","    pil_image = base64_to_pil(output)\n","    return pil_image\n","\n","gr.close_all()\n","demo = gr.Interface(fn=generate,\n","                    inputs=[\n","                        gr.Textbox(label=\"Your prompt\"),\n","                        gr.Textbox(label=\"Negative prompt\"),\n","                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n","                                 info=\"In how many steps will the denoiser denoise the image?\"),\n","                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n","                                  info=\"Controls how much the text prompt influences the result\"),\n","                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n","                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n","                    ],\n","                    outputs=[gr.Image(label=\"Result\")],\n","                    title=\"Image Generation with Stable Diffusion\",\n","                    description=\"Generate any image with Stable Diffusion\",\n","                    allow_flagging=\"never\"\n","                    )\n","\n","demo.launch(share=True, server_port=int(os.environ['PORT2']))"],"metadata":{"id":"ZqGCtxtN_9kO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo.close()"],"metadata":{"id":"2feMP9RT__E1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## `gr.Blocks()` to the rescue!"],"metadata":{"id":"HA4AXpFZABuX"}},{"cell_type":"code","source":["with gr.Blocks() as demo:\n","    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n","    prompt = gr.Textbox(label=\"Your prompt\")\n","    with gr.Row():\n","        with gr.Column():\n","            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n","            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n","                      info=\"In many steps will the denoiser denoise the image?\")\n","            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n","                      info=\"Controls how much the text prompt influences the result\")\n","            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n","            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n","            btn = gr.Button(\"Submit\")\n","        with gr.Column():\n","            output = gr.Image(label=\"Result\")\n","\n","    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n","gr.close_all()\n","demo.launch(share=True, server_port=int(os.environ['PORT3']))"],"metadata":{"id":"fxCNYPFrADPP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with gr.Blocks() as demo:\n","    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n","    with gr.Row():\n","        with gr.Column(scale=4):\n","            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n","        with gr.Column(scale=1, min_width=50):\n","            btn = gr.Button(\"Submit\") #Submit button side by side!\n","    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n","            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n","            with gr.Row():\n","                with gr.Column():\n","                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n","                      info=\"In many steps will the denoiser denoise the image?\")\n","                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n","                      info=\"Controls how much the text prompt influences the result\")\n","                with gr.Column():\n","                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n","                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n","    output = gr.Image(label=\"Result\") #Move the output up too\n","\n","    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n","\n","gr.close_all()\n","demo.launch(share=True, server_port=int(os.environ['PORT4']))"],"metadata":{"id":"x1gX0ysdAE38"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gr.close_all()"],"metadata":{"id":"-Ckz1jCqAGjf"},"execution_count":null,"outputs":[]}]}